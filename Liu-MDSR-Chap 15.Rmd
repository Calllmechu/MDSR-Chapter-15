---
title: "R Notebook"
output: html_notebook
---
## Chapter 15
```{r}
library(mdsr)
library(dplyr)
library(RCurl)
library(stringr)
library(tidyr)
library(aRxiv)
library(lubridate)
library(tm)
library(wordcloud)
library(rvest)
library(tidyr)
library(methods)
library(twitteR)
library(RSQLite)
library(ggmap)
```
## Section 15.1



##Section 15.1.1
```{r}
# pg 355
macbeth_url <- "http://www.gutenberg.org/cache/epub/1129/pg1129.txt"
Macbeth_raw <- RCurl::getURL(macbeth_url)

```
```{r}
#pg 355-356
data("Macbeth_raw")
macbeth <- strsplit(Macbeth_raw, "\r\n")[[1]]
length(macbeth)

```
```{r}
#pg356
macbeth[300:310]

```

```{r}
#pg356
macbeth_lines <- grep(" MACBETH", macbeth, value = TRUE)
length(macbeth_lines)

head(macbeth_lines)

```
```{r}
#pg 357
length(grep(" MACDUFF", macbeth))

```
```{r}
#pg 357
length(grep(" MACBETH", macbeth))

length(grepl(" MACBETH", macbeth))

```
```{r}
#pg 357
identical(macbeth[grep(" MACBETH", macbeth)],
          macbeth[grepl(" MACBETH", macbeth)])

```

```{r}
#pg 357
pattern <- " MACBETH"
grep(pattern, macbeth, value = TRUE) %>%
  str_extract(pattern) %>%
  head()

```

```{r}
#pg 358
head(grep("MAC.", macbeth, value = TRUE))

head(grep("MACBETH\\.", macbeth, value = TRUE))

```
```{r}
#pg 358
head(grep("MAC[B-Z]", macbeth, value = TRUE))

```
```{r}
#pg 358
head(grep("MAC(B|D)", macbeth, value = TRUE))
```

```{r}
#pg 359
head(grep("^ MAC[B-Z]", macbeth, value = TRUE))

```
```{r}
#pg 359
head(grep("^ ?MAC[B-Z]", macbeth, value = TRUE))
head(grep("^ *MAC[B-Z]", macbeth, value = TRUE))
head(grep("^ +MAC[B-Z]", macbeth, value = TRUE))
```
## Section 15.1.2
```{r}
#pg 360
Macbeth <- grepl(" MACBETH\\.", macbeth)
LadyMacbeth <- grepl(" LADY MACBETH\\.", macbeth)
Banquo <- grepl(" BANQUO\\.", macbeth)
Duncan <- grepl(" DUNCAN\\.", macbeth)

```
```{r}
#pg 360
speaker_freq <- data.frame(Macbeth, LadyMacbeth, Banquo, Duncan) %>%
  mutate(line = 1:length(macbeth)) %>%
  gather(key = "character", value = "speak", -line) %>%
  mutate(speak = as.numeric(speak)) %>%
  filter(line > 218 & line < 3172)
glimpse(speaker_freq)

```

```{r}
#pg 360
acts_idx <- grep("^ACT [I|V]+", macbeth)
acts_labels <- str_extract(macbeth[acts_idx], "^ACT [I|V]+")
acts <- data.frame(line = acts_idx, labels = acts_labels)

```
```{r}
#pg 360
ggplot(data = speaker_freq, aes(x = line, y = speak)) +
  geom_smooth(aes(color = character), method = "loess", se = 0, span = 0.4) +
  geom_vline(xintercept = acts_idx, color = "darkgray", lty = 3) +
  geom_text(data = acts, aes(y = 0.085, label = labels),
            hjust = "left", color = "darkgray") +
  ylim(c(0, NA)) + xlab("Line Number") + ylab("Proportion of Speeches")
```

##Section 15.2
```{r}
#pg 361
DataSciencePapers <- arxiv_search(query = '"Data Science"', limit = 200)
data(DataSciencePapers)
head(DataSciencePapers)
```
```{r}
#pg 362
DataSciencePapers <- DataSciencePapers %>%
  mutate(submitted = ymd_hms(submitted), updated = ymd_hms(updated))
glimpse(DataSciencePapers)

```
```{r}
#pg 362
tally(~ year(submitted), data = DataSciencePapers)

```
```{r}
#pg 362
DataSciencePapers %>%
  filter(year(submitted) == 2007) %>%
  glimpse()

```
```{r}
#pg 363
tally(~ primary_category, data = DataSciencePapers)

```
```{r}
#pg 363
DataSciencePapers %>%
  mutate(field = str_extract(primary_category, "^[a-z,-]+")) %>%
  tally(x = ~field) %>%
  sort()
```

## Section 15.2.1

```{r}
#pg 364
Corpus <- with(DataSciencePapers, VCorpus(VectorSource(abstract)))
Corpus[[1]] %>%
  as.character() %>%
  strwrap()

```
```{r}
#pg 364
Corpus <- Corpus %>%
  tm_map(stripWhitespace) %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removeWords, stopwords("english"))
strwrap(as.character(Corpus[[1]]))

```
## Section 15.2.2
```{r}
#pg 365
wordcloud(Corpus, max.words = 30, scale = c(8, 1),
          colors = topo.colors(n = 30), random.color = TRUE)
```
## section 15.2.3
```{r}
#pg 366
DTM <- DocumentTermMatrix(Corpus, control = list(weighting = weightTfIdf))
DTM

```
```{r}
#pg 366
findFreqTerms(DTM, lowfreq = 0.8)

```

```{r}
#pg 367
DTM %>% as.matrix() %>%
  apply(MARGIN = 2, sum) %>%
  sort(decreasing = TRUE) %>%
  head(9)

```
```{r}
#pg 367
findAssocs(DTM, terms = "statistics", corlimit = 0.5)
findAssocs(DTM, terms = "mathematics", corlimit = 0.5)
```
## Section 15.3


## Section 15.3.1
```{r}
#pg 367-368
url <- "http://en.wikipedia.org/wiki/List_of_songs_recorded_by_the_Beatles"
tables <- url %>%
read_html() %>%
html_nodes(css = "table")
songs <- html_table(tables[[4]])
glimpse(songs)
```


```{r}
#pg 368
songs <- songs %>%
  mutate(Song = gsub('\\"', "", Song), Year = as.numeric(Year)) %>%
  rename(songwriters = `Songwriter(s)`)
```
```{r}
#pg 368
tally(~songwriters, data = songs) %>%
  sort(decreasing = TRUE) %>%
  head()

```

```{r}
#pg 368
length(grep("McCartney", songs$songwriters))
length(grep("Lennon", songs$songwriters))
```
```{r}
#pg369
length(grep("(McCartney|Lennon)", songs$songwriters))
```
```{r}
#pg369
length(grep("(McCartney|Lennon).*(McCartney|Lennon)", songs$songwriters))
```
```{r}
#pg369
songs %>%
  filter(grepl("(McCartney|Lennon).*(McCartney|Lennon)", songwriters)) %>%
  select(Song) %>%
  head()
```
```{r}
#pg 369
song_titles <- VCorpus(VectorSource(songs$Song)) %>%
  tm_map(removeWords, stopwords("english")) %>%
  DocumentTermMatrix(control = list(weighting = weightTfIdf))
findFreqTerms(song_titles, 15)

```

## Section 15.3.2

```{r}
#pg 370
setup_twitter_oauth(consumer_key = "u2UthjbK6YHyQSp4sPk6yjsuV",
                    consumer_secret = "sC4mjd2WME5nH1FoWeSTuSy7JCP5DHjNtTYU1X6BwQ1vPZ0j3v",
                    access_token = "1365606414-7vPfPxStYNq6kWEATQlT8HZBd4G83BBcX4VoS9T",
                    access_secret = "0hJq9KYC3eBRuZzJqSacmtJ4PNJ7tNLkGrQrVl00JHirs")

```

```{r}
#pg 370
tweets <- searchTwitter("#datascience", lang = "en", n = 1000,
                        retryOnRateLimit = 100)
class(tweets)
class(tweets[[1]])

```

```{r}
#pg 370
tweet_df <- twListToDF(tweets) %>% as.tbl()
tweet_df %>%
  select(text) %>%
  head()
```
```{r}
#pg 370
ggplot(data = tweet_df, aes(x = nchar(text))) +
  geom_density(size = 2) +
  geom_vline(xintercept = 140) +
  scale_x_continuous("Number of Characters")

```

```{r}
#pg 370
tweet_df %>%
  filter(nchar(text) > 140) %>%
  select(text)

```
```{r}
#pg 371
ggplot(data = tweet_df, aes(x = retweetCount)) +
  geom_density(size = 2)
```
```{r}
#pg 372
tweet_df %>% filter(!is.na(longitude))
```
```{r}
#pg 372
tweet_db <- tempfile()
register_sqlite_backend(tweet_db)
store_tweets_db(tweets)
```
```{r}
#pg 373
tweets_src <- src_sqlite(tweet_db)
old_tweets <- tweets_src %>% tbl("tweets")
glimpse(old_tweets)
```
```{r}
#pg 373
big_data_tweets <- old_tweets %>%
  collect() %>%
  filter(grepl("#bigdata", text))
nrow(big_data_tweets) / nrow(collect(old_tweets))
```
##Section 15.4

##Section 15.5








This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
